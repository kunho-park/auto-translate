"""
ë°”ë‹ë¼ ë§ˆì¸í¬ë˜í”„íŠ¸ ë²ˆì—­ ë°ì´í„°ë¡œ Glossary êµ¬ì¶• ëª¨ë“ˆ

ë°”ë‹ë¼ ë§ˆì¸í¬ë˜í”„íŠ¸ì˜ en_us.jsonê³¼ ko_kr.jsonì„ ì½ì–´ì„œ
LLMì„ í™œìš©í•´ ì¼ê´€ì„± ìˆëŠ” ìš©ì–´ ì‚¬ì „(Glossary)ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.
"""

import asyncio
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional

from langchain_core.output_parsers import PydanticOutputParser
from langchain_google_genai import ChatGoogleGenerativeAI

from src.prompts.vanilla_glossary_prompts import create_vanilla_glossary_prompt

from .json_translator import Glossary, GlossaryEntry

logger = logging.getLogger(__name__)


class VanillaGlossaryBuilder:
    """ë°”ë‹ë¼ ë§ˆì¸í¬ë˜í”„íŠ¸ ë²ˆì—­ ë°ì´í„°ë¡œ glossaryë¥¼ êµ¬ì¶•í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(
        self,
        source_lang_file: str = "src/assets/vanilla_minecraft_assets/versions/1.21.5/en_us.json",
        target_lang_file: str = "src/assets/vanilla_minecraft_assets/versions/1.21.5/ko_kr.json",
        target_language: str = "í•œêµ­ì–´",
    ):
        self.source_lang_file = Path(source_lang_file)
        self.target_lang_file = Path(target_lang_file)
        self.target_language = target_language

        # ë²ˆì—­ ë°ì´í„° ì €ì¥
        self.vanilla_translations: Dict[str, str] = {}

    async def load_vanilla_translations(self) -> Dict[str, str]:
        """ë°”ë‹ë¼ ë§ˆì¸í¬ë˜í”„íŠ¸ ë²ˆì—­ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        logger.info("ë°”ë‹ë¼ ë§ˆì¸í¬ë˜í”„íŠ¸ ë²ˆì—­ ë°ì´í„° ë¡œë“œ ì‹œì‘")

        try:
            # ì†ŒìŠ¤ ì–¸ì–´ íŒŒì¼ ë¡œë“œ
            if not self.source_lang_file.exists():
                logger.error(
                    f"ì†ŒìŠ¤ ì–¸ì–´ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.source_lang_file}"
                )
                return {}

            with open(self.source_lang_file, "r", encoding="utf-8") as f:
                source_data = json.load(f)

            # íƒ€ê²Ÿ ì–¸ì–´ íŒŒì¼ ë¡œë“œ
            if not self.target_lang_file.exists():
                logger.error(
                    f"íƒ€ê²Ÿ ì–¸ì–´ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.target_lang_file}"
                )
                return {}

            with open(self.target_lang_file, "r", encoding="utf-8") as f:
                target_data = json.load(f)

            # ë§¤ì¹­ë˜ëŠ” ë²ˆì—­ ìŒ ì¶”ì¶œ
            translations = {}
            for key in source_data:
                if key in target_data:
                    source_text = source_data[key].strip()
                    target_text = target_data[key].strip()

                    # ìœ íš¨í•œ ë²ˆì—­ ìŒë§Œ ì¶”ê°€
                    if (
                        source_text
                        and target_text
                        and source_text != target_text
                        and len(source_text) > 1
                        and len(target_text) > 1
                    ):
                        translations[source_text] = target_text

            self.vanilla_translations = translations
            logger.info(
                f"ë°”ë‹ë¼ ë§ˆì¸í¬ë˜í”„íŠ¸ ë²ˆì—­ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(translations)}ê°œ ë²ˆì—­ ìŒ"
            )
            return translations

        except Exception as e:
            logger.error(f"ë°”ë‹ë¼ ë²ˆì—­ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}

    async def build_vanilla_glossary(
        self,
        max_entries_per_batch: int = 200,
        max_concurrent_requests: int = 3,
        max_retries: int = 3,
        progress_callback: Optional[callable] = None,
    ) -> List[GlossaryEntry]:
        """ë°”ë‹ë¼ ë²ˆì—­ ë°ì´í„°ë¥¼ í™œìš©í•´ LLMìœ¼ë¡œ glossaryë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤."""
        if not self.vanilla_translations:
            await self.load_vanilla_translations()

        if not self.vanilla_translations:
            logger.warning("ë°”ë‹ë¼ ë²ˆì—­ ë°ì´í„°ê°€ ì—†ì–´ glossary êµ¬ì¶•ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return []

        logger.info(
            f"ë°”ë‹ë¼ glossary êµ¬ì¶• ì‹œì‘: {len(self.vanilla_translations)}ê°œ ë²ˆì—­ ìŒ"
        )

        # ë²ˆì—­ ë°ì´í„°ë¥¼ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°
        translation_items = list(self.vanilla_translations.items())
        batches = [
            translation_items[i : i + max_entries_per_batch]
            for i in range(0, len(translation_items), max_entries_per_batch)
        ]

        logger.info(f"ì´ {len(batches)}ê°œ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬")

        # ì§„í–‰ë¥  ì½œë°± í˜¸ì¶œ
        if progress_callback:
            progress_callback(
                "ğŸ® ë°”ë‹ë¼ ì‚¬ì „ êµ¬ì¶• ì¤‘",
                0,
                len(batches),
                f"ë°”ë‹ë¼ ë§ˆì¸í¬ë˜í”„íŠ¸ ë²ˆì—­ ë°ì´í„° {len(self.vanilla_translations)}ê°œë¡œ ì‚¬ì „ êµ¬ì¶• ì‹œì‘",
            )

        # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ
        semaphore = asyncio.Semaphore(max_concurrent_requests)
        all_glossary_entries = []

        # ë°°ì¹˜ë³„ë¡œ ë³‘ë ¬ ì²˜ë¦¬
        tasks = [
            self._process_vanilla_batch(
                batch,
                batch_idx + 1,
                len(batches),
                semaphore,
                progress_callback,
                max_retries,
            )
            for batch_idx, batch in enumerate(batches)
        ]

        batch_results = await asyncio.gather(*tasks, return_exceptions=True)

        # ê²°ê³¼ ìˆ˜ì§‘
        for batch_idx, result in enumerate(batch_results):
            if isinstance(result, Exception):
                logger.error(f"ë°°ì¹˜ {batch_idx + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {result}")
            elif result:
                all_glossary_entries.extend(result.terms)

        # ì§„í–‰ë¥  ì½œë°± í˜¸ì¶œ (ì™„ë£Œ)
        if progress_callback:
            progress_callback(
                "ğŸ® ë°”ë‹ë¼ ì‚¬ì „ êµ¬ì¶• ì™„ë£Œ",
                len(batches),
                len(batches),
                f"ì´ {len(all_glossary_entries)}ê°œ ìš©ì–´ê°€ í¬í•¨ëœ ë°”ë‹ë¼ ì‚¬ì „ êµ¬ì¶• ì™„ë£Œ",
            )

        logger.info(f"ë°”ë‹ë¼ glossary êµ¬ì¶• ì™„ë£Œ: {len(all_glossary_entries)}ê°œ ìš©ì–´")
        return all_glossary_entries

    async def _process_vanilla_batch(
        self,
        batch: List[tuple],
        batch_num: int,
        total_batches: int,
        semaphore: asyncio.Semaphore,
        progress_callback: Optional[callable] = None,
        max_retries: int = 3,
    ) -> Glossary:
        """ë°”ë‹ë¼ ë²ˆì—­ ë°°ì¹˜ë¥¼ ì²˜ë¦¬í•˜ì—¬ glossary í•­ëª©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        async with semaphore:
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            if progress_callback:
                progress_callback(
                    "ğŸ® ë°”ë‹ë¼ ì‚¬ì „ êµ¬ì¶• ì¤‘",
                    batch_num - 1,
                    total_batches,
                    f"ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘ ({len(batch)}ê°œ í•­ëª©)",
                )

            # ë°°ì¹˜ë¥¼ JSON í˜•íƒœë¡œ êµ¬ì„±
            batch_data = {source: target for source, target in batch}

            # ì¬ì‹œë„ ë¡œì§ êµ¬í˜„
            last_error = None
            for attempt in range(max_retries + 1):  # 0ë²ˆ ì‹œë„ë¶€í„° max_retriesê¹Œì§€
                try:
                    # ì¬ì‹œë„ ì‹œì—ëŠ” temperatureë¥¼ ì¡°ê¸ˆì”© ì˜¬ë¦¼
                    temperature = (
                        0.1 if attempt == 0 else min(0.3, 0.1 + attempt * 0.05)
                    )

                    # LLM í”„ë¡¬í”„íŠ¸ ìƒì„± (ì¬ì‹œë„ ì‹œ ë” ëª…í™•í•œ ì§€ì‹œì‚¬í•­ ì¶”ê°€)
                    prompt = self._create_vanilla_glossary_prompt(
                        batch_data, attempt > 0
                    )

                    if attempt > 0:
                        logger.info(
                            f"ğŸ”„ ë°°ì¹˜ {batch_num} ë°”ë‹ë¼ ì‚¬ì „ êµ¬ì¶• ì¬ì‹œë„ {attempt}/{max_retries} (temperature={temperature})"
                        )
                        # ì¬ì‹œë„ ì‹œ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                        if progress_callback:
                            progress_callback(
                                "ğŸ® ë°”ë‹ë¼ ì‚¬ì „ êµ¬ì¶• ì¤‘",
                                batch_num - 1,
                                total_batches,
                                f"ë°°ì¹˜ {batch_num}/{total_batches} ì¬ì‹œë„ ì¤‘ ({attempt}/{max_retries})",
                            )

                    # LLM í˜¸ì¶œ (íƒ€ì„ì•„ì›ƒ ì¶”ê°€)
                    llm = ChatGoogleGenerativeAI(
                        model="gemini-2.5-pro", temperature=temperature
                    )
                    # PydanticParser ì‚¬ìš©
                    parser = PydanticOutputParser(pydantic_object=Glossary)
                    prompt_with_format = (
                        prompt + "\n\n" + parser.get_format_instructions()
                    )

                    # 30ì´ˆ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ LLM í˜¸ì¶œ
                    response = await asyncio.wait_for(
                        llm.ainvoke(prompt_with_format), timeout=240
                    )

                    # ì‘ë‹µì´ ë¬¸ìì—´ì¸ì§€ í™•ì¸ í›„ íŒŒì‹±
                    if hasattr(response, "content"):
                        response_text = response.content
                    else:
                        response_text = str(response)

                    result = parser.parse(response_text)

                    # ì„±ê³µ ì‹œ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                    if progress_callback:
                        success_msg = f"ë°°ì¹˜ {batch_num}/{total_batches} ì™„ë£Œ"
                        if attempt > 0:
                            success_msg += f" (ì¬ì‹œë„ {attempt}íšŒ í›„ ì„±ê³µ)"
                        success_msg += (
                            f" ({len(result.terms) if result else 0}ê°œ ìš©ì–´ ìƒì„±)"
                        )

                        progress_callback(
                            "ğŸ® ë°”ë‹ë¼ ì‚¬ì „ êµ¬ì¶• ì¤‘",
                            batch_num,
                            total_batches,
                            success_msg,
                        )

                    if attempt > 0:
                        logger.info(f"âœ… ë°°ì¹˜ {batch_num} ë°”ë‹ë¼ ì‚¬ì „ êµ¬ì¶• ì¬ì‹œë„ ì„±ê³µ")

                    logger.info(
                        f"ë°°ì¹˜ {batch_num} ì™„ë£Œ: {len(result.terms) if result else 0}ê°œ ìš©ì–´ ìƒì„±"
                    )

                    return result or Glossary(terms=[])

                except asyncio.TimeoutError:
                    last_error = asyncio.TimeoutError("LLM í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (240ì´ˆ)")
                    logger.warning(
                        f"â° ë°°ì¹˜ {batch_num} LLM í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1}/{max_retries + 1})"
                    )

                    # íƒ€ì„ì•„ì›ƒ ì‹œ ë” ê¸´ ëŒ€ê¸° ì‹œê°„
                    if attempt < max_retries:
                        await asyncio.sleep(min(5.0, (attempt + 1) * 1.0))

                except Exception as e:
                    last_error = e
                    error_type = type(e).__name__
                    logger.warning(
                        f"âš ï¸ ë°°ì¹˜ {batch_num} ë°”ë‹ë¼ ì‚¬ì „ êµ¬ì¶• ì‹¤íŒ¨ ({error_type}) (ì‹œë„ {attempt + 1}/{max_retries + 1}): {e}"
                    )

                    # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì ì‹œ ëŒ€ê¸°
                    if attempt < max_retries:
                        await asyncio.sleep(
                            min(3.0, (attempt + 1) * 0.5)
                        )  # 0.5ì´ˆ, 1ì´ˆ, 1.5ì´ˆ, 2ì´ˆ, 2.5ì´ˆ, 3ì´ˆ ëŒ€ê¸°

            # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ
            logger.error(
                f"âŒ ë°°ì¹˜ {batch_num} ë°”ë‹ë¼ ì‚¬ì „ êµ¬ì¶• {max_retries + 1}íšŒ ëª¨ë‘ ì‹¤íŒ¨: {last_error}"
            )

            # ì‹¤íŒ¨í•´ë„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            if progress_callback:
                progress_callback(
                    "ğŸ® ë°”ë‹ë¼ ì‚¬ì „ êµ¬ì¶• ì¤‘",
                    batch_num,
                    total_batches,
                    f"ë°°ì¹˜ {batch_num}/{total_batches} ì‹¤íŒ¨ (ì¬ì‹œë„ {max_retries}íšŒ í›„)",
                )

            return Glossary(terms=[])

    def _create_vanilla_glossary_prompt(
        self, batch_data: Dict[str, str], is_retry: bool = False
    ) -> str:
        """ë°”ë‹ë¼ ë²ˆì—­ ë°ì´í„°ë¡œ glossary ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        return create_vanilla_glossary_prompt(
            batch_data, self.target_language, is_retry
        )

    async def save_vanilla_glossary(
        self,
        glossary_entries: List[GlossaryEntry],
        output_path: str = "vanilla_glossary.json",
    ) -> None:
        """ìƒì„±ëœ ë°”ë‹ë¼ glossaryë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            glossary_data = [entry.dict() for entry in glossary_entries]

            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(glossary_data, f, ensure_ascii=False, indent=2)

            logger.info(
                f"ë°”ë‹ë¼ glossary ì €ì¥ ì™„ë£Œ: {output_path} ({len(glossary_entries)}ê°œ ìš©ì–´)"
            )

        except Exception as e:
            logger.error(f"ë°”ë‹ë¼ glossary ì €ì¥ ì‹¤íŒ¨: {e}")

    async def load_vanilla_glossary(
        self, glossary_path: str = "vanilla_glossary.json"
    ) -> List[GlossaryEntry]:
        """ì €ì¥ëœ ë°”ë‹ë¼ glossaryë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            if not Path(glossary_path).exists():
                logger.warning(
                    f"ë°”ë‹ë¼ glossary íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {glossary_path}"
                )
                return []

            with open(glossary_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            glossary_entries = [GlossaryEntry(**item) for item in data]
            logger.info(f"ë°”ë‹ë¼ glossary ë¡œë“œ ì™„ë£Œ: {len(glossary_entries)}ê°œ ìš©ì–´")
            return glossary_entries

        except Exception as e:
            logger.error(f"ë°”ë‹ë¼ glossary ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

    async def create_or_load_vanilla_glossary(
        self,
        glossary_path: str = "vanilla_glossary.json",
        force_rebuild: bool = False,
        max_entries_per_batch: int = 200,
        max_concurrent_requests: int = 3,
        max_retries: int = 3,
        progress_callback: Optional[callable] = None,
    ) -> List[GlossaryEntry]:
        """ë°”ë‹ë¼ glossaryë¥¼ ìƒì„±í•˜ê±°ë‚˜ ê¸°ì¡´ íŒŒì¼ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤."""

        # í•œêµ­ì–´ì¸ ê²½ìš° ë¯¸ë¦¬ ì¤€ë¹„ëœ ì‚¬ì „ íŒŒì¼ í™•ì¸
        if self.target_language == "í•œêµ­ì–´":
            preset_glossary_path = "src/assets/vanilla_glossary/ko_kr.json"

            # ë¯¸ë¦¬ ì¤€ë¹„ëœ ì‚¬ì „ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
            if Path(preset_glossary_path).exists():
                logger.info("ë¯¸ë¦¬ ì¤€ë¹„ëœ í•œêµ­ì–´ ë°”ë‹ë¼ ì‚¬ì „ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
                try:
                    return await self.load_vanilla_glossary(preset_glossary_path)
                except Exception as e:
                    logger.warning(f"ë¯¸ë¦¬ ì¤€ë¹„ëœ ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ë¡œì§ ì‚¬ìš©: {e}")

        # ê¸°ì¡´ íŒŒì¼ì´ ìˆê³  ì¬êµ¬ì¶•ì„ ê°•ì œí•˜ì§€ ì•ŠëŠ” ê²½ìš° ë¡œë“œ
        if Path(glossary_path).exists() and not force_rebuild:
            logger.info("ê¸°ì¡´ ë°”ë‹ë¼ glossary íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
            return await self.load_vanilla_glossary(glossary_path)

        # ìƒˆë¡œ êµ¬ì¶•
        logger.info("ë°”ë‹ë¼ glossaryë¥¼ ìƒˆë¡œ êµ¬ì¶•í•©ë‹ˆë‹¤.")
        glossary_entries = await self.build_vanilla_glossary(
            max_entries_per_batch=max_entries_per_batch,
            max_concurrent_requests=max_concurrent_requests,
            max_retries=max_retries,
            progress_callback=progress_callback,
        )

        # ì €ì¥
        if glossary_entries:
            await self.save_vanilla_glossary(glossary_entries, glossary_path)

        return glossary_entries


# í¸ì˜ í•¨ìˆ˜ë“¤
async def create_vanilla_glossary(
    output_path: str = "vanilla_glossary.json",
    force_rebuild: bool = False,
    max_entries_per_batch: int = 200,
    max_concurrent_requests: int = 3,
    max_retries: int = 3,
    progress_callback: Optional[callable] = None,
) -> List[GlossaryEntry]:
    """ë°”ë‹ë¼ ë§ˆì¸í¬ë˜í”„íŠ¸ glossaryë¥¼ ìƒì„±í•˜ëŠ” í¸ì˜ í•¨ìˆ˜"""
    builder = VanillaGlossaryBuilder()
    return await builder.create_or_load_vanilla_glossary(
        glossary_path=output_path,
        force_rebuild=force_rebuild,
        max_entries_per_batch=max_entries_per_batch,
        max_concurrent_requests=max_concurrent_requests,
        max_retries=max_retries,
        progress_callback=progress_callback,
    )


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    async def test_vanilla_glossary():
        logger.basicConfig(level=logging.INFO)

        def progress_callback(title, current, total, message):
            print(f"{title}: {current}/{total} - {message}")

        glossary_entries = await create_vanilla_glossary(
            output_path="test_vanilla_glossary.json",
            force_rebuild=True,
            max_entries_per_batch=100,
            max_concurrent_requests=2,
            max_retries=3,
            progress_callback=progress_callback,
        )

        print(f"ìƒì„±ëœ ë°”ë‹ë¼ glossary ìš©ì–´ ìˆ˜: {len(glossary_entries)}")

        # ëª‡ ê°œ ì˜ˆì‹œ ì¶œë ¥
        for i, entry in enumerate(glossary_entries[:5]):
            print(f"{i + 1}. {entry.original}")
            for meaning in entry.meanings:
                print(f"   -> {meaning.translation} (ë¬¸ë§¥: {meaning.context})")

    asyncio.run(test_vanilla_glossary())

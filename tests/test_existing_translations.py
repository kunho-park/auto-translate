"""
ê¸°ì¡´ ë²ˆì—­ ë°ì´í„°ë¥¼ í™œìš©í•œ 1ì°¨ ì‚¬ì „ êµ¬ì¶• ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
"""

import asyncio
import json
import logging
import sys
import tempfile
from pathlib import Path
from typing import Dict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.modpack.load import ModpackLoader
from src.translators.json_translator import (
    JSONTranslator,
    TranslatorState,
    create_primary_glossary_node,
)
from src.translators.modpack_translator import ModpackTranslator

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.DEBUG, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class TestExistingTranslations:
    """ê¸°ì¡´ ë²ˆì—­ ë°ì´í„° ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    def __init__(self):
        self.test_data_path = Path(__file__).parent / "test_data" / "modpack"
        self.temp_dir = None

    def setup_test_environment(self):
        """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •"""
        print("ğŸ”§ í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì • ì¤‘...")

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ í™•ì¸
        if not self.test_data_path.exists():
            raise FileNotFoundError(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {self.test_data_path}")

        print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ: {self.test_data_path}")

        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„± (ê¸€ë¡œì‹œë¦¬ ì €ì¥ìš©)
        self.temp_dir = tempfile.mkdtemp()
        print(f"âœ… ì„ì‹œ ë””ë ‰í† ë¦¬: {self.temp_dir}")

    def cleanup_test_environment(self):
        """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì •ë¦¬"""
        if self.temp_dir:
            import shutil

            shutil.rmtree(self.temp_dir, ignore_errors=True)
            print(f"ğŸ§¹ ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬: {self.temp_dir}")

    def test_modpack_loader_file_collection(self):
        """ModpackLoaderì˜ íŒŒì¼ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“ í…ŒìŠ¤íŠ¸ 1: ModpackLoader íŒŒì¼ ìˆ˜ì§‘")

        # íƒ€ê²Ÿ ì–¸ì–´ê°€ ì—†ëŠ” ê²½ìš°
        loader_no_target = ModpackLoader(
            modpack_path=str(self.test_data_path), source_lang="en_us", target_lang=None
        )

        files_no_target, _, _ = loader_no_target.load_translation_files()
        print(f"  íƒ€ê²Ÿ ì–¸ì–´ ì—†ìŒ: {len(files_no_target)}ê°œ íŒŒì¼ ìˆ˜ì§‘")

        # íƒ€ê²Ÿ ì–¸ì–´ê°€ ìˆëŠ” ê²½ìš°
        loader_with_target = ModpackLoader(
            modpack_path=str(self.test_data_path),
            source_lang="en_us",
            target_lang="ko_kr",
        )

        files_with_target, _, _ = loader_with_target.load_translation_files()
        print(f"  íƒ€ê²Ÿ ì–¸ì–´ í¬í•¨: {len(files_with_target)}ê°œ íŒŒì¼ ìˆ˜ì§‘")

        # ì–¸ì–´ íƒ€ì…ë³„ ë¶„ë¥˜
        source_files = [f for f in files_with_target if f.get("lang_type") == "source"]
        target_files = [f for f in files_with_target if f.get("lang_type") == "target"]
        other_files = [f for f in files_with_target if f.get("lang_type") == "other"]

        print(f"    - ì†ŒìŠ¤ íŒŒì¼(en_us): {len(source_files)}ê°œ")
        print(f"    - íƒ€ê²Ÿ íŒŒì¼(ko_kr): {len(target_files)}ê°œ")
        print(f"    - ê¸°íƒ€ íŒŒì¼: {len(other_files)}ê°œ")

        # íŒŒì¼ ìŒ ì¶œë ¥
        for source_file in source_files:
            print(f"    ğŸ“„ ì†ŒìŠ¤: {Path(source_file['input']).name}")
        for target_file in target_files:
            print(f"    ğŸ“„ íƒ€ê²Ÿ: {Path(target_file['input']).name}")

        assert len(files_with_target) >= len(files_no_target), (
            "íƒ€ê²Ÿ ì–¸ì–´ í¬í•¨ ì‹œ ë” ë§ì€ íŒŒì¼ì´ ìˆ˜ì§‘ë˜ì–´ì•¼ í•¨"
        )
        assert len(source_files) > 0, "ì†ŒìŠ¤ ì–¸ì–´ íŒŒì¼ì´ ìˆì–´ì•¼ í•¨"
        assert len(target_files) > 0, "íƒ€ê²Ÿ ì–¸ì–´ íŒŒì¼ì´ ìˆì–´ì•¼ í•¨"

        print("  âœ… íŒŒì¼ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ í†µê³¼")
        return loader_with_target

    def test_existing_translation_analysis(self, loader: ModpackLoader):
        """ê¸°ì¡´ ë²ˆì—­ ë°ì´í„° ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ” í…ŒìŠ¤íŠ¸ 2: ê¸°ì¡´ ë²ˆì—­ ë°ì´í„° ë¶„ì„")

        # ê¸°ì¡´ ë²ˆì—­ ë¶„ì„
        existing_translations = loader.analyze_existing_translations()
        combined_translations = loader.get_all_existing_translations()

        print(f"  ë¶„ì„ëœ íŒŒì¼: {len(existing_translations)}ê°œ")
        print(f"  ì¶”ì¶œëœ ë²ˆì—­ ìŒ: {len(combined_translations)}ê°œ")

        # ë²ˆì—­ ìŒ ìƒ˜í”Œ ì¶œë ¥
        sample_count = min(5, len(combined_translations))
        print(f"  ë²ˆì—­ ìŒ ìƒ˜í”Œ ({sample_count}ê°œ):")
        for i, (source, target) in enumerate(
            list(combined_translations.items())[:sample_count]
        ):
            print(f"    {i + 1}. '{source}' â†’ '{target}'")

        assert len(combined_translations) > 0, "ê¸°ì¡´ ë²ˆì—­ ë°ì´í„°ê°€ ì¶”ì¶œë˜ì–´ì•¼ í•¨"

        # ë²ˆì—­ í’ˆì§ˆ ê²€ì¦ (ì†ŒìŠ¤ì™€ íƒ€ê²Ÿì´ ë‹¤ë¥¸ì§€)
        valid_translations = 0
        for source, target in combined_translations.items():
            if (
                source.strip() != target.strip()
                and len(source.strip()) > 0
                and len(target.strip()) > 0
            ):
                valid_translations += 1

        print(f"  ìœ íš¨í•œ ë²ˆì—­ ìŒ: {valid_translations}/{len(combined_translations)}ê°œ")
        assert valid_translations > 0, "ìœ íš¨í•œ ë²ˆì—­ ìŒì´ ìˆì–´ì•¼ í•¨"

        print("  âœ… ê¸°ì¡´ ë²ˆì—­ ë¶„ì„ í…ŒìŠ¤íŠ¸ í†µê³¼")
        return combined_translations

    def test_primary_glossary_creation(self, existing_translations: Dict[str, str]):
        """1ì°¨ ì‚¬ì „ êµ¬ì¶• í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“– í…ŒìŠ¤íŠ¸ 3: 1ì°¨ ì‚¬ì „ êµ¬ì¶•")

        # í…ŒìŠ¤íŠ¸ ìƒíƒœ ìƒì„±
        test_state = TranslatorState(
            parsed_json={},
            target_language="í•œêµ­ì–´",
            max_retries=3,
            max_tokens_per_chunk=3000,
            max_concurrent_requests=5,
            delay_between_requests_ms=200,
            placeholders={},
            id_to_text_map={},
            important_terms=[],
            processed_json={},
            translation_map={},
            translated_json={},
            final_json="",
            retry_count=0,
            error=None,
            glossary_path=None,
            use_glossary=True,
            progress_callback=None,
            existing_translations=existing_translations,
            primary_glossary=[],
        )

        # 1ì°¨ ì‚¬ì „ êµ¬ì¶• ì‹¤í–‰
        result_state = create_primary_glossary_node(test_state)
        primary_glossary = result_state["primary_glossary"]

        print(f"  ìƒì„±ëœ 1ì°¨ ì‚¬ì „ ìš©ì–´ ìˆ˜: {len(primary_glossary)}ê°œ")

        # 1ì°¨ ì‚¬ì „ ìƒ˜í”Œ ì¶œë ¥
        sample_count = min(5, len(primary_glossary))
        print(f"  1ì°¨ ì‚¬ì „ ìƒ˜í”Œ ({sample_count}ê°œ):")
        for i, term in enumerate(primary_glossary[:sample_count]):
            meanings = ", ".join([m.translation for m in term.meanings])
            print(f"    {i + 1}. '{term.original}' â†’ [{meanings}]")

        assert len(primary_glossary) > 0, "1ì°¨ ì‚¬ì „ì´ ìƒì„±ë˜ì–´ì•¼ í•¨"

        # ì‚¬ì „ í’ˆì§ˆ ê²€ì¦
        for term in primary_glossary:
            assert len(term.original) > 0, "ì›ë³¸ ìš©ì–´ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì•ˆë¨"
            assert len(term.meanings) > 0, "ë²ˆì—­ì´ ë¹„ì–´ìˆìœ¼ë©´ ì•ˆë¨"
            for meaning in term.meanings:
                assert len(meaning.translation) > 0, "ë²ˆì—­ì´ ë¹„ì–´ìˆìœ¼ë©´ ì•ˆë¨"

        print("  âœ… 1ì°¨ ì‚¬ì „ êµ¬ì¶• í…ŒìŠ¤íŠ¸ í†µê³¼")
        return primary_glossary

    async def test_json_translator_integration(
        self, existing_translations: Dict[str, str]
    ):
        """JSONTranslator í†µí•© í…ŒìŠ¤íŠ¸"""
        print("\nğŸ¤– í…ŒìŠ¤íŠ¸ 4: JSONTranslator í†µí•© í…ŒìŠ¤íŠ¸")

        # í…ŒìŠ¤íŠ¸ìš© JSON ë°ì´í„° (ê¸°ì¡´ ë²ˆì—­ì— í¬í•¨ëœ ìš©ì–´ë“¤ ì‚¬ìš©)
        test_data = {
            "welcome": "Welcome to the adventure!",
            "items": {
                "sword": "Magic Sword",
                "potion": "Healing Potion",
                "crystal": "Fire Crystal",
            },
            "messages": {
                "quest_complete": "Quest Completed!",
                "new_item": "You found a Magic Sword!",
            },
        }

        print(f"  í…ŒìŠ¤íŠ¸ ë°ì´í„°: {json.dumps(test_data, indent=2)}")

        # ê¸€ë¡œì‹œë¦¬ íŒŒì¼ ê²½ë¡œ
        glossary_path = Path(self.temp_dir) / "test_glossary.json"

        # JSONTranslator ìƒì„± ë° ë²ˆì—­ ì‹¤í–‰
        translator = JSONTranslator(glossary_path=str(glossary_path))

        print("  ë²ˆì—­ ì‹¤í–‰ ì¤‘... (ê¸°ì¡´ ë²ˆì—­ ë°ì´í„° í™œìš©)")

        # ì§„í–‰ë¥  ì½œë°± ì •ì˜
        def progress_callback(stage, current, total, message):
            print(f"    {stage}: {current}/{total} - {message}")

        try:
            translated_result = await translator.translate(
                test_data,
                target_language="í•œêµ­ì–´",
                use_glossary=True,
                max_retries=1,  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì¤„ì„
                existing_translations=existing_translations,
                progress_callback=progress_callback,
            )

            print("  ë²ˆì—­ ê²°ê³¼:")
            print(f"    {translated_result}")

            # ê²°ê³¼ ê²€ì¦
            assert isinstance(translated_result, str), "ë²ˆì—­ ê²°ê³¼ëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•¨"
            translated_data = json.loads(translated_result)
            assert isinstance(translated_data, dict), "ë²ˆì—­ ê²°ê³¼ëŠ” JSON ê°ì²´ì—¬ì•¼ í•¨"

            print("  âœ… JSONTranslator í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼")

        except Exception as e:
            print(f"  âš ï¸ JSONTranslator í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (API í‚¤ ì—†ìŒ ë“±): {e}")
            print("  ğŸ”„ ëª¨ì˜ í…ŒìŠ¤íŠ¸ë¡œ ëŒ€ì²´...")

            # ëª¨ì˜ ë²ˆì—­ ê²°ê³¼
            mock_result = json.dumps(
                {
                    "welcome": "ëª¨í—˜ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!",
                    "items": {
                        "sword": "ë§ˆë²• ê²€",
                        "potion": "ì¹˜ìœ  ë¬¼ì•½",
                        "crystal": "í™”ì—¼ ìˆ˜ì •",
                    },
                    "messages": {
                        "quest_complete": "í€˜ìŠ¤íŠ¸ ì™„ë£Œ!",
                        "new_item": "ë§ˆë²• ê²€ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!",
                    },
                },
                ensure_ascii=False,
                indent=2,
            )

            print(f"  ëª¨ì˜ ë²ˆì—­ ê²°ê³¼: {mock_result}")
            print("  âœ… ëª¨ì˜ í…ŒìŠ¤íŠ¸ í†µê³¼")

    async def test_modpack_translator_integration(self):
        """ModpackTranslator í†µí•© í…ŒìŠ¤íŠ¸"""
        print("\nğŸ¯ í…ŒìŠ¤íŠ¸ 5: ModpackTranslator í†µí•© í…ŒìŠ¤íŠ¸")

        # ê¸€ë¡œì‹œë¦¬ íŒŒì¼ ê²½ë¡œ
        glossary_path = Path(self.temp_dir) / "modpack_glossary.json"

        # ì§„í–‰ë¥  ì½œë°± ì •ì˜
        def progress_callback(stage, current, total, message):
            print(f"    {stage}: {current}/{total} - {message}")

        # ModpackTranslator ìƒì„±
        modpack_translator = ModpackTranslator(
            modpack_path=str(self.test_data_path),
            glossary_path=str(glossary_path),
            source_lang="en_us",
            target_language="í•œêµ­ì–´",
            max_concurrent_requests=2,  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì¤„ì„
            delay_between_requests_ms=100,  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì¤„ì„
            progress_callback=progress_callback,
        )

        try:
            # ë²ˆì—­ ë°ì´í„° ìˆ˜ì§‘
            print("  ë²ˆì—­ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            integrated_data = await modpack_translator.collect_all_translations()

            print(f"  ìˆ˜ì§‘ëœ ë°ì´í„°: {len(integrated_data)}ê°œ í•­ëª©")
            print(
                f"  ê¸°ì¡´ ë²ˆì—­ ë°ì´í„°: {len(modpack_translator.existing_translations)}ê°œ ìŒ"
            )

            # ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥
            sample_count = min(3, len(integrated_data))
            print(f"  ìˆ˜ì§‘ ë°ì´í„° ìƒ˜í”Œ ({sample_count}ê°œ):")
            for i, (key, value) in enumerate(
                list(integrated_data.items())[:sample_count]
            ):
                print(f"    {i + 1}. '{key}': '{value[:50]}...'")

            # ê¸°ì¡´ ë²ˆì—­ ìƒ˜í”Œ ì¶œë ¥
            existing_sample_count = min(
                3, len(modpack_translator.existing_translations)
            )
            print(f"  ê¸°ì¡´ ë²ˆì—­ ìƒ˜í”Œ ({existing_sample_count}ê°œ):")
            for i, (source, target) in enumerate(
                list(modpack_translator.existing_translations.items())[
                    :existing_sample_count
                ]
            ):
                print(f"    {i + 1}. '{source}' â†’ '{target}'")

            assert len(integrated_data) > 0, "í†µí•© ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì–´ì•¼ í•¨"
            assert len(modpack_translator.existing_translations) > 0, (
                "ê¸°ì¡´ ë²ˆì—­ ë°ì´í„°ê°€ ìˆì–´ì•¼ í•¨"
            )

            print("  âœ… ModpackTranslator í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼")

        except Exception as e:
            print(f"  âš ï¸ ModpackTranslator í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            print("  ğŸ”„ ê¸°ë³¸ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ë¡œ ëŒ€ì²´...")

            # ê¸°ë³¸ ìˆ˜ì§‘ë§Œ í…ŒìŠ¤íŠ¸
            assert modpack_translator.loader is not None, "ë¡œë”ê°€ ì´ˆê¸°í™”ë˜ì–´ì•¼ í•¨"
            print("  âœ… ê¸°ë³¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ í†µê³¼")

    def print_test_summary(self):
        """í…ŒìŠ¤íŠ¸ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ‰ ê¸°ì¡´ ë²ˆì—­ ë°ì´í„° í™œìš© ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("=" * 60)
        print()
        print("ğŸ“‹ í…ŒìŠ¤íŠ¸ëœ ê¸°ëŠ¥:")
        print("  âœ… ModpackLoaderì˜ ì†ŒìŠ¤/íƒ€ê²Ÿ íŒŒì¼ ìˆ˜ì§‘")
        print("  âœ… ê¸°ì¡´ ë²ˆì—­ ë°ì´í„° ì¶”ì¶œ ë° ë¶„ì„")
        print("  âœ… 1ì°¨ ì‚¬ì „ êµ¬ì¶•")
        print("  âœ… JSONTranslator ê¸°ì¡´ ë²ˆì—­ ë°ì´í„° í™œìš©")
        print("  âœ… ModpackTranslator í†µí•© ë™ì‘")
        print()
        print("ğŸš€ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print()
        print("ğŸ’¡ ì´ì œ ë‹¤ìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        print("  - ê¸°ì¡´ ë²ˆì—­ íŒŒì¼ì´ ìë™ìœ¼ë¡œ ê°ì§€ë¨")
        print("  - 1ì°¨ ì‚¬ì „ì´ ê¸°ì¡´ ë²ˆì—­ìœ¼ë¡œë¶€í„° êµ¬ì¶•ë¨")
        print("  - LLMì´ 1ì°¨ ì‚¬ì „ì„ ì°¸ê³ í•˜ì—¬ ë” ì •í™•í•œ ë²ˆì—­ ìƒì„±")
        print("  - ë²ˆì—­ ì¼ê´€ì„±ì´ í¬ê²Œ í–¥ìƒë¨")

    async def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        try:
            # í™˜ê²½ ì„¤ì •
            self.setup_test_environment()

            # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            print("ğŸš€ ê¸°ì¡´ ë²ˆì—­ ë°ì´í„° í™œìš© ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
            print("=" * 60)

            # 1. ModpackLoader í…ŒìŠ¤íŠ¸
            loader = self.test_modpack_loader_file_collection()

            # 2. ê¸°ì¡´ ë²ˆì—­ ë¶„ì„ í…ŒìŠ¤íŠ¸
            existing_translations = self.test_existing_translation_analysis(loader)

            # 3. 1ì°¨ ì‚¬ì „ êµ¬ì¶• í…ŒìŠ¤íŠ¸
            primary_glossary = self.test_primary_glossary_creation(
                existing_translations
            )

            # 4. JSONTranslator í†µí•© í…ŒìŠ¤íŠ¸
            await self.test_json_translator_integration(existing_translations)

            # 5. ModpackTranslator í†µí•© í…ŒìŠ¤íŠ¸
            await self.test_modpack_translator_integration()

            # í…ŒìŠ¤íŠ¸ ìš”ì•½
            self.print_test_summary()

        except Exception as e:
            print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback

            traceback.print_exc()
        finally:
            # í™˜ê²½ ì •ë¦¬
            self.cleanup_test_environment()


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    test_runner = TestExistingTranslations()
    await test_runner.run_all_tests()


if __name__ == "__main__":
    # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(main())
